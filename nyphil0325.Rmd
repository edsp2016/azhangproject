---
title: "Reflection on NY Phil ¨C The NY Phil as a lens on changes in classical music culture"
output: html_document
---
Around the turn of the century, New York City became the arts center of the world. A major factor was the establishment and expansion of the New York Philharmonic which not only encouraged the flourishing of American musicians but also attracted musicians from all over the world to NYC. In this research, I would like to study the performance history of the New York Philharmonic, analyze and visualize the changes of diversity in composers and the form of stardom in performers over time.  

I would first like to study changes in diversity in composers over time using factors like repertoire, composer, performer and their origins. Originally, these were very limited but with time the music increased in diversity as the number of performances increased. Therefore, I want to compute a popularity score to even out the increase of numbers of performances. I want to see with the rise of NYC as the center of art and culture, will there be a change from the strongly Euro-centric, older(deceased), male composers. I will get nationality, gender, birth year data by scraping websites like Wikipedia.  

to do:
scraping:
1.composer nationality: https://en.wikipedia.org/wiki/Category:Classical_composers_by_nationality (into a table )
2.female composer https://en.wikipedia.org/wiki/List_of_female_composers_by_birth_year
3.composer with born year https https://en.wikipedia.org/wiki/List_of_21st-century_classical_composers


1. I computed the popularity scores for each composer in each season. I first read the XML file and found the number of every composers in all season and put them in a table. I then sumed up the total number of performance in each seaon. I got the popularity score by dividing the number of performance for each composers in each season by the total number of performance in each season. 
```{r, eval=FALSE}
require("XML")
#require(RCurl)
#xmlfile <- xmlParse("complete.xml")
xmlfile <- xmlParse("~/GitHub/azhangproject/complete.xml")
rootnode = xmlRoot(xmlfile) #gives content of root

incrementComp <- function(composer_stats, c, season){
  if (is.null(composer_stats[c, season])) {
    composer_stats[c, season] <- 1
  } else if (is.na(composer_stats[c,season])) {
    composer_stats[c, season] <- 1
  } else {
    composer_stats[c, season] <- composer_stats[c, season] + 1
  }
  return(composer_stats)
}

composerBySeasonComplete <- data.frame()
for (seas in 1:xmlSize(rootnode)) {
  # DEBUG: cat(seas, "\n")
  firstlist <- xmlToList(rootnode[[seas]])
  season <- firstlist$season
  season <- paste("Season",season,sep=".")
  works <- firstlist$worksInfo
  if (is.list(works)) {     # sometimes works is actually empty
      for (i in 1:length(works)) {
        if (!is.null(works[[i]]$composerName)) {    #sometimes there is no composer
          composerBySeasonComplete <- incrementComp(composerBySeasonComplete, works[[i]]$composerName,season)
        }
      }
    }
}
colnames(composerBySeasonComplete)[1]="composers"
#write.csv(composerBySeasonComplete, "composerBySeasonComplete.csv")
```

the cleaned data look like:
```{r}
composerBySeasonComplete <- read.csv("~/GitHub/azhangproject/composerBySeasonComplete.csv", row.names=1)
composerBySeasonComplete[1:5,1:5]
```

the popularity score table
```{r,eval=FALSE}
require(base)
composerBySeasonComplete[is.na(composerBySeasonComplete)] <- 0
composerBySeasonComplete1=composerBySeasonComplete[2:175]
composerBySeasonComplete2=composerBySeasonComplete[1]
popScoreComposerComplete=data.frame()
totalNumConcert=colSums(composerBySeasonComplete1, na.rm=TRUE)
for ( i in 1:2652){
  popScoreComposerComplete[i,]=composerBySeasonComplete1[i,]/totalNumConcert
  i=i+1
}
popScoreComposerComplete=cbind(composerBySeasonComplete2,popScoreComposerComplete)
#write.csv(popScoreComposerComplete,"popScoreComposerComplete.csv")
```

the popularity score table looks like:
```{r}
popScoreComposerComplete <- read.csv("~/GitHub/azhangproject/popScoreComposerComplete.csv", row.names=1)
popScoreComposerComplete[1:5,1:5]
```

top ten popular composers
```{r}
popScoreSumComp=rowSums(popScoreComposerComplete[2:175],na.rm=TRUE)
popScoreSumComp=cbind(popScoreComposerComplete[1],popScoreSumComp)
popScoreSumComp1=popScoreSumComp[order(-popScoreSumComp$popScoreSumComp),]
#test1=rowSums(popScoreSumComp1$popScoreSumComp)
head(popScoreSumComp1,20)
```

graphing specific composers'popularity scores over time.  
```{r}
# test=popScoreComposerComplete[1,]
# test=test[2:175]
# test=unlist(test)
# par(mar = rep(1,4))
#require(ggplot2)
#points(test,y=NULL)
#plot(as.double(popScoreComposerComplete[1,2:ncol(popScoreComposerComplete)]), type = "l")
require(ggplot2)
qplot(seq_along(as.double(popScoreComposerComplete[770,2:ncol(popScoreComposerComplete)])),as.double(popScoreComposerComplete[770,2:ncol(popScoreComposerComplete)]))+geom_line()+ylim(0,1)+geom_area(colour="black")
```

2.woman composers:
I scraped wikipedia page on a list of women composers (https://en.wikipedia.org/wiki/List_of_female_composers_by_birth_year) in python and read it in R. I matched the name of women composers with the composers in the popularity score table and computed the proportion of women composers's works performed in each season and graphed it. 
```{r}
library(png)
library(grid)
img01 <- readPNG("2016-03-26.png")
grid.raster(img01)
```

```{r}
womancomposers <- read.csv("womancomposers.csv", header = FALSE, quote = "'")
womenAsChar <- character(ncol(womancomposers))
for (i in 1:ncol(womancomposers)) {
  womanString <- as.character(womancomposers[1,i])
  if (substr(womanString, 1, 1) == " ") womanString <- substr(womanString, 2, nchar(womanString))
  if (substr(womanString, 1, 1) == "u") womanString <- substr(womanString, 2, nchar(womanString))
  womenAsChar[i] <- womanString # as.character(womancomposers[1,i])
}

l=c()
for ( i in 1:length(womenAsChar)){
  l=c(l,which(womenAsChar[i]==popScoreComposerComplete$composers))
}

womancom=popScoreComposerComplete[l,]
womancomoScore=colSums(womancom[2:175])
plot(womancomoScore, type = "l")

malecom=popScoreComposerComplete[-l,]
malecomoScore=colSums(malecom[2:175])
plot(malecomoScore, type = "l")

require(ggplot2)
qplot(seq_along(womancomoScore),womancomoScore)+geom_line()+ylim(0,1)+geom_area(colour="black")
```

3. composers nationalities
I got the most of the composers nationality scores by scraping this page: (https://en.wikipedia.org/wiki/Category:Classical_composers_by_nationality) using the following python code
```{r}
img02 <- readPNG("2016-03-26b.png")
grid.raster(img02)
```

some pages, for example the American composer page (https://en.wikipedia.org/w/index.php?title=Category:American_classical_composers) has multiple pages, and it is hard to go through every page in my code. So I scraped every page by clicking by hand and rbind them together in R

```{r}
img03 <- readPNG("scrapeNationality2.png")
grid.raster(img03)
```

I stacked the data from multiple pages and cleaned it. 
```{r}
american1=read.csv("americantest1.csv", header = FALSE ,encoding = "UTF-8")
american2=read.csv("americantest2.csv", header = FALSE ,encoding = "UTF-8")
american3=read.csv("americantest3.csv", header = FALSE ,encoding = "UTF-8")
american4=read.csv("americantest4.csv", header = FALSE ,encoding = "UTF-8")
american5=read.csv("americantest5.csv", header = FALSE ,encoding = "UTF-8")
american6=read.csv("americantest6.csv", header = FALSE ,encoding = "UTF-8")
american7=read.csv("americantest7.csv", header = FALSE ,encoding = "UTF-8")
american=c(american1,american2,american3,american4,american5,american6,american7)
american=unique(unlist(american))
#american0 <- as.factor(american[,1])
american1.0=gsub("\\(composer)|\\(pianist)|\\(conductor)|\\(guitarist)|\\(musician)|\\ (musicologist)|\\(singer-songwriter)|\\ (Fluxus musician)","",american)
american1.1=strsplit(as.character(american1.0)," ")

#matching method one. change the name format of american composer list into last name ",  " first name and exact match with pop score table
american1.2=list(rep(0,length(american1.1)))
for ( i in 1:length(american1.1)){
  if (length(american1.1[[i]])>1)
    american1.2[i]=paste(american1.1[[i]][length(american1.1[[i]])],american1.1[[i]][1],sep=",  ")
}
american1.2=american1.2[!is.na(american1.2)]
l=list(rep(0, length(american1.2)))
l=c()
for ( i in 1:length(american1.2)){
  l=c(l,which(american1.2[i]==popScoreComposerComplete$composers))
}
americans=popScoreComposerComplete$composers[l]
americansPop=popScoreComposerComplete[l,]
americansPopSum=colSums(americansPop[2:175])
qplot(seq_along(americansPopSum),americansPopSum)+geom_line()+ylim(0,1)+geom_area(colour="black")

#matching method 2. 
# k=c()
# test=american1.1=strsplit(as.character(american1.0)," ")
# for ( i in 1:length(american1.1)){
#   for ( j in 1:length(test)){
#     if(length(which(american1.1[[i]][1]==test[[j]][length(test[[j]])]))>0 && 
#      length(which(american1.1[[i]][length(test[[i]])]==test[[j]][1]))>0){
#       k=c(k,i)
#     }
#   }
# }
```

top twenty american composers
```{r}
americanTop=rowSums(americansPop[2:175],na.rm=TRUE)
americanTop=cbind(as.data.frame(americans)[1],americanTop)
americanTop1=americanTop[order(-americanTop$americanTop),]
#test1=rowSums(popScoreSumComp1$popScoreSumComp)
head(americanTop1,20)
```

3. Scraping composer birth and death year. 
The web pages' structure for different time period is different. I scraped the classical era composer's birth and death year page (https://en.wikipedia.org/wiki/List_of_Classical-era_composers) in python with the following code.
```{r}
img04 <- readPNG("classicalCode.png")
grid.raster(img04)
```

I use rvest to scrape the page for romantic era composers page(https://en.wikipedia.org/wiki/List_of_Romantic-era_composers), twentieth century composers' page(https://en.wikipedia.org/wiki/List_of_20th-century_classical_composers), and twenty first century composers' page (https://en.wikipedia.org/wiki/List_of_21st-century_classical_composers). 
```{r,eval=FALSE}
require(mosaic)
library(rvest)
url <- 'https://en.wikipedia.org/wiki/List_of_20th-century_classical_composers'
html <- read_html(url, encoding = "UTF-8")
tables <- html_table(html, fill=TRUE)
tables=tables[[2]]
tables=tables[1:3]
for (i in 1:nrow(tables)){
  test=unlist(strsplit(tables$Name[i],""))
  n=(length(test)+1)/2
  test1=test[1:n]
  test2=do.call(paste, c(as.list(test1), sep=""))
  tables$Name1[i]=test2
}
twentiethC=tables[2:4]

#change variable names
names(tables)[names(tables)=="Year of birth"] <- "birth"
names(tables)[names(tables)=="Year of death"] <- "death"

#substitute NAs with current year
tables$death[is.na(tables$death)] <- 2016
#find match. see if the composer appears in NY phil or not
l=c()
for (i in 1:(length(tables))){
  l=c(l,which(tables$Name[i]==popScoreComposerComplete$composers))
}
#find the col number of the first non 0 value and get the year
```

```{r,eval=FALSE}
url <- 'https://en.wikipedia.org/wiki/List_of_21st-century_classical_composers'
html <- read_html(url, encoding = , encoding="UTF-8")
tables <- html_table(html, fill=TRUE)
tables=tables[[2]]
tables=tables[1:3]
write.csv(tables,"test0328.csv")
tables=read.csv("test0328.csv", encoding="UTF-8")
for (i in 1:nrow(tables)){
  test=unlist(strsplit(tables$Name[i],""))
  n=(length(test)+1)/2
  test1=test[1:n]
  test2=do.call(paste, c(as.list(test1), sep=""))
  tables$Name1[i]=test2
}
twentyFirstC=tables[2:4]
```

to do:
1. better matching algorithms for women composer list and nationality list with popularity score by first and last name rather than full name
2. remove (composer) from the american list
2. read non English letters in xml file and wiki list of composer file
3. matching algorith for death year and pop score: year die>earliest work present season
4. better graph
